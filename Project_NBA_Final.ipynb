{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, linear_model, tree, preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.datasets import make_regression, make_hastie_10_2\n",
    "from scipy.cluster.vq import vq, kmeans, kmeans2, whiten\n",
    "%matplotlib inline\n",
    "os.chdir(r\"U:\\RemoteApp\")\n",
    "\n",
    "stats = pd.read_excel(r\"nba-players-stats\\Seasons_Stats.xlsx\") #mother data set for performance stats\n",
    "stats = stats[stats['Tm']!='TOT'] #remove players with team name TOT. These entries were traded during the regular season.\n",
    "salary17 = pd.read_csv(r\"salary\\salary.csv\") #data set for 2017 salary\n",
    "aggr = {'Pos':'first','Tm':'last','G':'sum','GS':'sum','MP':'sum','PER':'mean','TS%':'mean','3PAr':'mean','FTr':'mean',\n",
    "        'ORB%':'mean','DRB%':'mean','TRB%':'mean','AST%':'mean','STL%':'mean','BLK%':'mean','TOV%':'mean','USG%':'mean',\n",
    "        'OWS':'mean','DWS':'mean','WS':'mean','OBPM':'mean','DBPM':'mean','BPM':'mean','VORP':'mean','FG':'sum','FGA':'sum',\n",
    "        'FG%':'mean','3P':'sum','3P%':'mean','2P':'sum','2P%':'mean','eFG%':'mean','FT':'sum','FT%':'mean','ORB':'sum',\n",
    "        'DRB':'sum','TRB':'sum','AST':'sum','STL':'sum','BLK':'sum','TOV':'sum','PF':'sum','PTS':'sum'}\n",
    "\n",
    "#segregate and group by player names for each season from 2013-16 to generate unique data points\n",
    "stats13 = stats[stats[\"Year\"] == 2013.0]\n",
    "stats13 = stats13.groupby([\"Player\"], as_index=False).agg(aggr)\n",
    "stats14 = stats[stats[\"Year\"] == 2014.0]\n",
    "stats14 = stats14.groupby([\"Player\"], as_index=False).agg(aggr)\n",
    "stats15 = stats[stats[\"Year\"] == 2015.0]\n",
    "stats15 = stats15.groupby([\"Player\"], as_index=False).agg(aggr)\n",
    "stats16 = stats[stats[\"Year\"] == 2016.0]\n",
    "stats16 = stats16.groupby([\"Player\"], as_index=False).agg(aggr)\n",
    "stats17 = stats[stats[\"Year\"] == 2017.0]\n",
    "stats17 = stats17.groupby([\"Player\"], as_index=False).agg(aggr)\n",
    "\n",
    "#consolidate 2013-16 data\n",
    "stats1316 = pd.concat([stats13,stats14,stats15,stats16], ignore_index=True)\n",
    "salary17 = salary17.groupby([\"Player\"]).agg({'Tm':'last', 'season17_18':'last'})\n",
    "\n",
    "#merge salary with performance stats and clean the data\n",
    "stats17 = pd.merge(stats17, salary17, how='left', on='Player')\n",
    "stats17 = stats17.drop(['Tm_y'], axis=1); stats17 = stats17.drop(['PER'], axis=1)\n",
    "stats17 = stats17.rename(columns={'Tm_x':'Tm', 'season17_18':'SALARY'})\n",
    "\n",
    "#segregate data for Indiana Pacers\n",
    "pacers = stats17[stats17.Tm == \"IND\"]\n",
    "stats17 = stats17[stats17.Tm != \"IND\"]\n",
    "cols = ['TS%','TRB%','AST%','TOV%','USG%','BPM','PF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "#from tqdm import tnrange, tqdm_notebook\n",
    "def fit_linear_reg(X,Y):\n",
    "    #Fit ridge linear regression model and return RSS and R squared values\n",
    "    model_k = linear_model.Ridge(alpha=.5)\n",
    "    model_k.fit(X,Y)\n",
    "    RSS = mean_squared_error(Y,model_k.predict(X)) * len(Y)\n",
    "    R_squared = model_k.score(X,Y)\n",
    "    return RSS, R_squared\n",
    "    \n",
    "#Initialization variables\n",
    "Y = stats1316.PER\n",
    "X = stats1316[['G','MP','TS%','TRB%','AST%','STL%','BLK%','TOV%','USG%','WS','BPM','VORP','FG%','3P%','FT%','PF','PTS']]\n",
    "k = 17\n",
    "X = X.fillna(0)\n",
    "Y = Y.fillna(0)\n",
    "RSS_list, R_squared_list, feature_list = [],[], []\n",
    "numb_features = []\n",
    "\n",
    "#Looping over k = 1 to k = 17 features in X\n",
    "#for k in tnrange(1,len(X.columns) + 1, desc = 'Loop...'):\n",
    "for k in range(1,len(X.columns) + 1):\n",
    "    #Looping over all possible combinations: from 17 choose k\n",
    "    for combo in itertools.combinations(X.columns,k):\n",
    "        tmp_result = fit_linear_reg(X[list(combo)],Y)#Store temp result \n",
    "        RSS_list.append(tmp_result[0])#Append lists\n",
    "        R_squared_list.append(tmp_result[1])\n",
    "        feature_list.append(combo)\n",
    "        numb_features.append(len(combo))   \n",
    "\n",
    "#Store in DataFrame\n",
    "df = pd.DataFrame({'numb_features': numb_features,'RSS': RSS_list, 'R_squared':R_squared_list,'features':feature_list})\n",
    "\n",
    "#Print the best features for no. of features\n",
    "df_min = df[df.groupby('numb_features')['RSS'].transform(min) == df['RSS']]\n",
    "df_max = df[df.groupby('numb_features')['R_squared'].transform(max) == df['R_squared']]\n",
    "display(df_min.head(8))\n",
    "display(df_max.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clean empty cells in dataframes\n",
    "stats1316 = stats1316.fillna(0)\n",
    "stats17 = stats17.fillna(0)\n",
    "\n",
    "#choose parameters and predictor for regression\n",
    "perf_var1316 = stats1316[cols] #training params\n",
    "perf_var17 = stats17[cols] #test params\n",
    "per = stats1316.PER\n",
    "\n",
    "#select best regression model\n",
    "#regr1 = linear_model.LinearRegression()\n",
    "regr1 = linear_model.Ridge(alpha=0.5)\n",
    "#regr1 = tree.DecisionTreeRegressor()\n",
    "#regr1 = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "#regr1 = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0, loss='huber')\n",
    "\n",
    "regr1.fit(perf_var1316, per) #fit the model based on training data\n",
    "per_pred = regr1.predict(perf_var17) #predict PER values for 2017\n",
    "stats17[\"PER\"] = per_pred; stats17 = stats17.sort_values(by=['PER'], ascending=False)\n",
    "\n",
    "#perform k-means clustering to categorize players based on performance and salary\n",
    "whitened = whiten(stats17[['PER','SALARY']].values) #normalize data\n",
    "centroids,_ = kmeans(whitened, 2)\n",
    "idx,_ = vq(whitened,centroids)\n",
    "#generate clustering scatterplot\n",
    "plt.plot(whitened[idx==0,0], whitened[idx==0,1], 'ob',\n",
    "         whitened[idx==1,0], whitened[idx==1,1],'og')\n",
    "plt.plot(centroids[:,1], centroids[:,1], 'sm', c='r', markersize='8')\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.show()\n",
    "\n",
    "print(\"Score: \"+str(regr1.score(perf_var1316, per)))\n",
    "print(stats17[['Player','PER']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#predict top 5 players in Indiana Pacers\n",
    "pacer_data = pacers[cols]\n",
    "pacers_pie = regr1.predict(pacer_data); pacers[\"PER\"] = pacers_pie\n",
    "pacers = pacers.sort_values(by=['PER'], ascending=False); print(pacers[['Player','PER', 'SALARY']])\n",
    "index = np.arange(len(pacers.PER))\n",
    "plt.bar(index, pacers['PER'], color=['g','g','g','g','g','b','b','b','b','b','b','b','b'])\n",
    "plt.xlabel('Players', fontsize=11)\n",
    "plt.ylabel('PER Score', fontsize=11)\n",
    "plt.xticks(index, pacers['Player'], fontsize=9, rotation=90)\n",
    "plt.title('Indiana Pacers - Player Ratings')\n",
    "plt.figure(figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top5 = pacers[:5] #segregate top 5 players in IND Pacers\n",
    "\n",
    "#calculate available salary cap for choosing remaining roster\n",
    "salary_cap = 114000000\n",
    "avail_sal = salary_cap - top5.iloc[:5,-2].sum()\n",
    "\n",
    "#calculate position based stats for top 5\n",
    "pos = top5.groupby([\"Pos\"], as_index=False).agg({'SALARY':'sum'}); temp = top5.Pos.value_counts().to_frame(); temp=temp.sort_values(by=['Pos'], ascending=True).reset_index()\n",
    "pos[\"Count\"] = temp['Pos']\n",
    "\n",
    "#create position based dataframes for rest of NBA\n",
    "pg = stats17[stats17['Pos']=='PG'].sort_values(by=['PER'], ascending=False)\n",
    "sg = stats17[stats17['Pos']=='SG'].sort_values(by=['PER'], ascending=False)\n",
    "pf = stats17[stats17['Pos']=='PF'].sort_values(by=['PER'], ascending=False)\n",
    "sf = stats17[stats17['Pos']=='SF'].sort_values(by=['PER'], ascending=False)\n",
    "c = stats17[stats17['Pos']=='C'].sort_values(by=['PER'], ascending=False)\n",
    "\n",
    "#create position based dataframes for IND Pacers\n",
    "ind_pg = pacers[pacers['Pos']=='PG'].sort_values(by=['PER'], ascending=False)\n",
    "ind_sg = pacers[pacers['Pos']=='SG'].sort_values(by=['PER'], ascending=False)\n",
    "ind_pf = pacers[pacers['Pos']=='PF'].sort_values(by=['PER'], ascending=False)\n",
    "ind_sf = pacers[pacers['Pos']=='SF'].sort_values(by=['PER'], ascending=False)\n",
    "ind_c = pacers[pacers['Pos']=='C'].sort_values(by=['PER'], ascending=False)\n",
    "\n",
    "#create salary and composition stats for rest of NBA\n",
    "nba_sg = [sg.SALARY.count(), sg.SALARY.mean(), sg.SALARY.count()/(stats17.Tm.nunique())]\n",
    "nba_sf = [sf.SALARY.count(), sf.SALARY.mean(), sf.SALARY.count()/(stats17.Tm.nunique())]\n",
    "nba_pg = [pg.SALARY.count(), pg.SALARY.mean(), pg.SALARY.count()/(stats17.Tm.nunique())]\n",
    "nba_c = [c.SALARY.count(), c.SALARY.mean(), c.SALARY.count()/(stats17.Tm.nunique())]\n",
    "nba_pf = [pf.SALARY.count(), pf.SALARY.mean(), pf.SALARY.count()/(stats17.Tm.nunique())]\n",
    "nba_sal = [stats17.SALARY.count(), stats17.SALARY.mean(), stats17.SALARY.count()/(stats17.Tm.nunique()+1)]\n",
    "\n",
    "#create budget allocation parameters(average budget, benchmarked budget) for each position in IND Pacers\n",
    "sg_budget = [ind_sg.SALARY.count(), ind_sg.SALARY.mean(), (ind_sg.SALARY.count()*nba_sg[1]*nba_sal[2])/pacers.SALARY.count()]\n",
    "sf_budget = [ind_sf.SALARY.count(), ind_sf.SALARY.mean(), (ind_sf.SALARY.count()*nba_sf[1]*nba_sal[2])/pacers.SALARY.count()]\n",
    "pg_budget = [ind_pg.SALARY.count(), ind_pg.SALARY.mean(), (ind_pg.SALARY.count()*nba_pg[1]*nba_sal[2])/pacers.SALARY.count()]\n",
    "c_budget = [ind_c.SALARY.count(), ind_c.SALARY.mean(), (ind_c.SALARY.count()*nba_c[1]*nba_sal[2])/pacers.SALARY.count()]\n",
    "pf_budget = [ind_pf.SALARY.count(), ind_pf.SALARY.mean(), (ind_pf.SALARY.count()*nba_pf[1]*nba_sal[2])/pacers.SALARY.count()]\n",
    "pac_budget = [pacers.SALARY.count(), pacers.SALARY.mean(), nba_sal[1]*nba_sal[2]]\n",
    "\n",
    "#calculate position-wise available budget for IND Pacers\n",
    "c_budget.append((c_budget[2]*salary_cap)/pac_budget[2])\n",
    "sg_budget.append((sg_budget[2]*salary_cap)/pac_budget[2])\n",
    "sf_budget.append((sf_budget[2]*salary_cap)/pac_budget[2])\n",
    "pg_budget.append(((pg_budget[2]*salary_cap)/pac_budget[2])+c_budget[3])\n",
    "pf_budget.append((pf_budget[2]*salary_cap)/pac_budget[2])\n",
    "pac_budget.append(salary_cap)\n",
    "\n",
    "#generate PG recommendations based on budget allocation and PER score\n",
    "final_pg = pg[pg['SALARY'] < (pg_budget[3]-top5.iloc[1:4,-2].sum())]; final_pg = final_pg[[\"Player\",\"SALARY\",\"PER\"]]\n",
    "final_pg = final_pg[:10]; final_pg = final_pg.sort_values(by=\"SALARY\",ascending=True); final_pg = final_pg.reset_index() \n",
    "final_pg = final_pg.drop(['index'], axis=1)\n",
    "\n",
    "#generate SG recommendations based on budget allocation and PER score\n",
    "final_sg = sg[sg['SALARY'] < sg_budget[3]]; final_sg = final_sg[[\"Player\",\"SALARY\",\"PER\"]]\n",
    "final_sg = final_sg[:10]; final_sg = final_sg.sort_values(by=\"SALARY\",ascending=True); final_sg = final_sg.reset_index()\n",
    "final_sg = final_sg.drop(['index'], axis=1)\n",
    "\n",
    "#generate SF recommendations based on budget allocation and PER score\n",
    "final_sf = sf[sf['SALARY'] < (sf_budget[3]-top5.iloc[0,-2])]; final_sf = final_sf[[\"Player\",\"SALARY\",\"PER\"]]\n",
    "final_sf = final_sf[:10]; final_sf = final_sf.sort_values(by=\"SALARY\",ascending=True); final_sf = final_sf.reset_index()\n",
    "final_sf = final_sf.drop(['index'], axis=1)\n",
    "\n",
    "#generate PF recommendations based on budget allocation and PER score\n",
    "final_pf = pf[pf['SALARY'] < (pf_budget[3]-top5.iloc[4,-2])]; final_pf = final_pf[[\"Player\",\"SALARY\",\"PER\"]]\n",
    "final_pf = final_pf[:10]; final_pf = final_pf.sort_values(by=\"SALARY\",ascending=True); final_pf = final_pf.reset_index()\n",
    "final_pf = final_pf.drop(['index'], axis=1)\n",
    "\n",
    "#logic to generate sample roster from our recommendations\n",
    "while True:\n",
    "    sample_pg = final_pg.sample(n=2)\n",
    "    sample_pf = final_pf.sample(n=2)\n",
    "    sample_sg = final_sg.sample(n=2)\n",
    "    sample_sf = final_sf.sample(n=2)\n",
    "    sample_roster = pd.concat([top5[['Player','SALARY','PER']],sample_pg, sample_pf, sample_sg, sample_sf], ignore_index=True)\n",
    "    if (sample_roster.SALARY.sum() <= salary_cap):\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(\"Salary cap available: \"+str(avail_sal)); print()\n",
    "print(\"PG Recommendations:\"); \n",
    "print(final_pg); print()\n",
    "print(\"SG Recommendations:\")\n",
    "print(final_sg); print()\n",
    "print(\"SF Recommendations:\")\n",
    "print(final_sf); print()\n",
    "print(\"PF Recommendations:\")\n",
    "print(final_pf); print()\n",
    "print(\"Sample Roster:\")\n",
    "print(sample_roster); print()\n",
    "print(\"Sample Roster Salary: \"+str(sample_roster.SALARY.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#generate descriptive stats and correlation matrix for performance stats\n",
    "print(stats17[cols].describe())\n",
    "print(stats1316[['TS%','TRB%','AST%','TOV%','USG%','BPM','PF','PER']].describe())\n",
    "plt.matshow(stats1316[['TS%','TRB%','AST%','TOV%','USG%','BPM','PF','PER']].corr())\n",
    "plt.yticks(range(len(stats1316[['TS%','TRB%','AST%','TOV%','USG%','BPM','PF','PER']].columns)), stats1316[['TS%','TRB%','AST%','TOV%','USG%','BPM','PF','PER']].columns)\n",
    "plt.xticks(range(len(stats1316[['TS%','TRB%','AST%','TOV%','USG%','BPM','PF','PER']].columns)), stats1316[['TS%','TRB%','AST%','TOV%','USG%','BPM','PF','PER']].columns, rotation='vertical')\n",
    "plt.colorbar()\n",
    "pd.plotting.scatter_matrix(stats1316[['TS%','TRB%','AST%','TOV%','USG%','BPM','PF','PER']],figsize=(10,10))\n",
    "pd.plotting.scatter_matrix(stats17[cols],figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([pacers,stats17])\n",
    "colist=[\"TS%\", \"PTS\", \"TRB\", \"AST\", \"TOV\", \"PF\", \"USG%\",\"BPM\",\"SALARY\",\"G\"]\n",
    "new_df= result[colist]\n",
    "desc_df=new_df.describe(include= \"all\")\n",
    "desc_df[colist]=desc_df[colist].round(2)\n",
    "print(desc_df.head(10))\n",
    "plt.figure(figsize=(16, 6))\n",
    "cust = {Tm: \"teal\" if Tm== \"IND\" else \"lightblue\" for Tm in result.Tm.unique()}\n",
    "sal_box = sns.boxplot(x='Tm',y='SALARY', data=result, width=0.6, palette=cust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density plot with shade\n",
    "sns.kdeplot(result.PER,shade=True,color='lightblue',legend=False).set_title('Distribution of predicted PER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density plot with shade\n",
    "sns.kdeplot(stats1316.PER,shade=True,color='lightblue',legend=False).set_title('Distribution of actual PER (2013-16)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_pos=result.groupby('Pos').mean().reset_index()\n",
    "by_pos=by_pos.sort_values(by='Pos')\n",
    "sns.barplot(x='PTS',y='Pos', data=by_pos, palette='Blues')\n",
    "plt.title(\"Season points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='TRB',y='Pos', data=by_pos, palette='Blues')\n",
    "plt.title(\"Total Rebounds (TRB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='AST',y='Pos', data=by_pos, palette='Blues')\n",
    "plt.title(\"Assists (AST)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='STL',y='Pos', data=by_pos, palette='Blues')\n",
    "plt.title(\"Steals (STL)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='TOV',y='Pos', data=by_pos, palette='Blues')\n",
    "plt.title(\"Turnover (TOV)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='BLK',y='Pos', data=by_pos, palette='Blues')\n",
    "plt.title(\"Blocks (BLK)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='PF',y='Pos', data=by_pos, palette='Blues')\n",
    "plt.title(\"Personal Fouls (PF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pos=result.groupby('Pos').agg({'SALARY':'mean','Tm':'count'})\n",
    "avg_pos['P_Tm']=(avg_pos['Tm']/30).round(0)\n",
    "avg_pos['av_sal']=(avg_pos['SALARY']/1000000).round(2)\n",
    "print(avg_pos.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
